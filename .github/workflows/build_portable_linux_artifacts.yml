name: Build Portable Linux Artifacts

on:
  workflow_dispatch:
    inputs:
      amdgpu_families:
        type: string
        default: gfx94X-dcgpu
      artifact_group:
        type: string
        default: gfx94X-dcgpu
      build_variant_label:
        type: string
        description: "A label for the build variant (ex: 'Release', 'ASAN')"
        default: "Release"
      build_variant_suffix:
        type: string
        description: "The build variant suffix (ex: 'asan' suffix -> 'gfx94X-dcgpu-asan')"
        default: ""
      build_variant_cmake_preset:
        type: string
        description: "The name of the cmake preset to use for this build variant, matching an entry in CMakePresets.json (ex: 'linux-release-asan')"
        default: ""
      package_version:
        type: string
        default: ADHOCBUILD
      expect_failure:
        type: boolean
        default: false
      extra_cmake_options:
        type: string

  workflow_call:
    inputs:
      package_version:
        type: string
        default: ADHOCBUILD
      amdgpu_families:
        type: string
      artifact_group:
        type: string
      build_variant_label:
        type: string
      build_variant_suffix:
        type: string
      build_variant_cmake_preset:
        type: string
      expect_failure:
        type: boolean
      extra_cmake_options:
        type: string

# See the details regarding permissions from the link:
# https://github.com/aws-actions/configure-aws-credentials?tab=readme-ov-file#oidc
permissions:
  contents: read

jobs:
  build_portable_linux_artifacts:
    name: Build (xfail ${{ inputs.expect_failure }})
    runs-on: azure-linux-scale-rocm
    continue-on-error: ${{ inputs.expect_failure }}
    timeout-minutes: 720 # 12 hour timeout
    permissions:
      id-token: write
    container:
      image: ghcr.io/rocm/therock_build_manylinux_x86_64@sha256:4443d9d710b9471e8ef658d509358bd92602498e67161b9280474bce0bb0decd
      options: -v /runner/config:/home/awsconfig/
    env:
      AWS_SHARED_CREDENTIALS_FILE: /home/awsconfig/credentials.ini
      CACHE_DIR: ${{ github.workspace }}/.container-cache
      # The ccache.conf will be written by setup_ccache.py before this gets used.
      CCACHE_CONFIGPATH: ${{ github.workspace }}/.ccache/ccache.conf
      AMDGPU_FAMILIES: ${{ inputs.amdgpu_families }}
      TEATIME_FORCE_INTERACTIVE: 0
      IS_PR_FROM_FORK: ${{ github.event.pull_request.head.repo.fork }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Install python deps
        run: |
          pip install -r requirements.txt

      # safe.directory must be set before Runner Health Status
      - name: Adjust git config
        run: |
          git config --global --add safe.directory $PWD
          git config fetch.parallel 10

      # TODO: We shouldn't be using a cache on actual release branches, but it
      # really helps for iteration time.
      - name: Setup ccache
        run: |
          ./build_tools/setup_ccache.py \
            --config-preset "github-oss-presubmit" \
            --dir "$(dirname $CCACHE_CONFIGPATH)" \
            --local-path "$CACHE_DIR/ccache"

      - name: Runner health status
        run: |
          ./build_tools/health_status.py

      - name: Test build_tools
        run: |
          python -m pytest build_tools/tests build_tools/github_actions/tests

      - name: Fetch sources
        timeout-minutes: 30
        run: |
          ./build_tools/fetch_sources.py --jobs 12

      - name: Configure Projects
        env:
          cmake_preset: ${{ inputs.build_variant_cmake_preset }}
          amdgpu_families: ${{ inputs.amdgpu_families }}
          package_version: ${{ inputs.package_version }}
          extra_cmake_options: ${{ inputs.extra_cmake_options }}
          BUILD_DIR: build
        run: |
          python3 build_tools/github_actions/build_configure.py --manylinux

      - name: Build therock-archives and therock-dist
        run: cmake --build build --target therock-archives therock-dist -- -k 0

      - name: Test Packaging
        if: ${{ github.event.repository.name == 'TheRock' }}
        run: |
          ctest --test-dir build --output-on-failure


      - name: Report
        if: ${{ !cancelled() }}
        shell: bash
        run: |
          mkdir -p build/logs

          # --- Collect machine and status info ---
          HOSTNAME=$(hostname)
          JOB_RESULT="${{ job.status }}"

          # Default outcomes
          BUILD_OUTCOME="unknown"
          BUILD_TEST_OUTCOME="unknown"

          # Detect build success/failure based on previous steps
          if [ "$JOB_RESULT" == "success" ]; then
            BUILD_OUTCOME="success"
          else
            BUILD_OUTCOME="failed"
          fi

          # Check if any test result file exists or use ctest return
          if [ -f "build/Testing/Temporary/LastTest.log" ]; then
            if grep -q "100% tests passed" build/Testing/Temporary/LastTest.log; then
              BUILD_TEST_OUTCOME="success"
            else
              BUILD_TEST_OUTCOME="failed"
            fi
          else
            # Default to same as build result if tests not run
            BUILD_TEST_OUTCOME="$BUILD_OUTCOME"
          fi

          if [ -d "./build" ]; then
            echo "Full SDK du:"
            echo "------------"
            du -h -d 1 build/dist/rocm
            echo "Artifact Archives:"
            echo "------------------"
            ls -lh build/artifacts/*.tar.xz
            echo "Artifacts:"
            echo "----------"
            du -h -d 1 build/artifacts
            echo "CCache Stats:"
            echo "-------------"
            ccache -s -v
            tail -v -n +1 .ccache/compiler_check_cache/* > build/logs/ccache_compiler_check_cache.log

            echo "Collecting build metrics and writing to JSON..."
            SDK_DU=$(du -h -d 1 build/dist/rocm 2>/dev/null | awk '{print $1, $2}' | jq -R -s -c 'split("\n")[:-1]')
            ARTIFACT_ARCHIVES=$(ls -lh build/artifacts/*.tar.xz 2>/dev/null | awk '{print $5, $9}' | jq -R -s -c 'split("\n")[:-1]')
            ARTIFACT_DU=$(du -h -d 1 build/artifacts 2>/dev/null | awk '{print $1, $2}' | jq -R -s -c 'split("\n")[:-1]')
            CCACHE_STATS=$(ccache -s -v 2>/dev/null | jq -R -s -c '.')

            jq -n \
              --arg workflow "${{ github.workflow }}" \
              --arg job_name "${{ github.job }}" \
              --arg job_result "$JOB_RESULT" \
              --arg run_id "${{ github.run_id }}" \
              --arg run_number "${{ github.run_number }}" \
              --arg repo "${{ github.repository }}" \
              --arg hostname "$HOSTNAME" \
              --arg timestamp "$(date -u '+%Y-%m-%dT%H:%M:%SZ')" \
              --arg build_outcome "$BUILD_OUTCOME" \
              --arg build_test_outcome "$BUILD_TEST_OUTCOME" \
              --argjson sdk_du "$SDK_DU" \
              --argjson artifact_archives "$ARTIFACT_ARCHIVES" \
              --argjson artifact_du "$ARTIFACT_DU" \
              --arg ccache_stats "$CCACHE_STATS" \
              '{
                workflow: $workflow,
                job_name: $job_name,
                job_result: $job_result,
                run_id: $run_id,
                run_number: $run_number,
                commit: $commit,
                repo: $repo,
                hostname: $hostname,
                timestamp: $timestamp,
                build_outcome: $build_outcome,
                build_test_outcome: $build_test_outcome,
                build: {
                  sdk_disk_usage: $sdk_du,
                  artifact_archives: $artifact_archives,
                  artifact_disk_usage: $artifact_du,
                  ccache_stats: $ccache_stats
                }
              }' > build/logs/build_report_${HOSTNAME}.json

            echo " JSON report written to build/logs/build_report_${HOSTNAME}.json"
          else
            echo "[ERROR] Build directory ./build does not exist. Skipping report!" | tee build/logs/error.log
            echo "        This should only happen if the CI is cancelled before the build step."
            exit 1
          fi

      - name: Upload build logs and JSONs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: "linux-build-logs-${{ runner.name || env.HOSTNAME }}"
          path: |
            build/logs/
          if-no-files-found: warn

      - name: Configure AWS Credentials for non-forked repos
        if: ${{ always() && !github.event.pull_request.head.repo.fork }}
        uses: aws-actions/configure-aws-credentials@00943011d9042930efac3dcd3a170e4273319bc8 # v5.1.0
        with:
          aws-region: us-east-2
          role-to-assume: arn:aws:iam::692859939525:role/therock-artifacts

      - name: Post Build Upload
        if: always()
        run: |
          python3 build_tools/github_actions/post_build_upload.py \
            --run-id ${{ github.run_id }} \
            --artifact-group "${{ inputs.artifact_group }}" \
            --build-dir build \
            --upload

      # - name: Upload job metrics to Redshift database
      #   if: ${{ always() && github.repository == 'ROCm/TheRock' && !github.event.pull_request.head.repo.fork }}
      #   env:
      #     RUN_ID: ${{ github.run_id }}
      #     ATTEMPT: ${{ github.run_attempt }}
      #   run: |
      #     # Fetch job summary and store it
      #     JOB_SUMMARY=$(python3 build_tools/github_actions/fetch_job_status.py)
      #     # Populate Redshift Database tables
      #     python3 build_tools/github_actions/populate_redshift_db.py \
      #       --api-output "$JOB_SUMMARY" \
      #       --redshift-cluster-endpoint "${{ secrets.THEROCK_REDSHIFT_CLUSTER_ENDPOINT }}" \
      #       --redshift-username  "${{ secrets.THEROCK_REDSHIFT_CLUSTER_USERNAME }}"\
      #       --dbname "${{ secrets.THEROCK_REDSHIFT_CLUSTER_DBNAME }}" \
      #       --redshift-password "${{ secrets.THEROCK_REDSHIFT_CLUSTER_PASSWORD }}" \
      #       --redshift-port "${{ secrets.THEROCK_REDSHIFT_CLUSTER_ACCESS_PORT }}" \
      #       --run-id ${{ github.run_number }}
