name: Build VLLM Docker

on:
  workflow_call:
    inputs:
      pytorch_base_image:
        description: The base image to use as FROM for vLLM base build (e.g., rocm/pytorch-private:rocm79_torchX)
        required: true
        type: string
      vllm_ref:
        description: Commit SHA, branch, or tag to checkout in ROCm/vllm
        required: true
        type: string
      vllm_repo:
        description: Git repo to clone for vLLM
        required: false
        type: string
        default: https://github.com/ROCm/vllm.git
      push:
        description: Whether to push the final image to Docker Hub
        required: false
        type: boolean
        default: true
      final_image_name:
        description: Final image repository/name
        required: false
        type: string
        default: rocm/pytorch-private
      rocm_version:
        description: ROCm version used to compose rocm_suffix
        required: false
        type: string
      amdgpu_family:
        description: AMDGPU family used to compose rocm_suffix
        required: false
        type: string
    outputs:
      vllm_tag:
        description: The final vLLM image tag that was built/pushed
        value: ${{ jobs.vllm.outputs.vllm_tag }}

  workflow_dispatch:
    inputs:
      pytorch_base_image:
        type: string
        required: true
      vllm_ref:
        type: string
        required: true
        description: Commit SHA, branch, or tag to checkout
      vllm_repo:
        type: string
        required: false
        default: https://github.com/ROCm/vllm.git
      push:
        type: boolean
        required: false
        default: true
      final_image_name:
        type: string
        required: false
        default: rocm/pytorch-private
      rocm_version:
        type: string
        required: false
        description: ROCm version used to compose rocm_suffix
      amdgpu_family:
        type: string
        required: false
        description: AMDGPU family used to compose rocm_suffix

permissions:
  contents: read

jobs:
  vllm:
    name: Build and Push VLLM Docker Image
    runs-on: ubuntu-24.04
    outputs:
      vllm_tag: ${{ steps.run.outputs.vllm_tag }}
    env:
      REGISTRY: docker.io

    steps:
      - name: Checkout repo (to get Python script)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3.7.1

      - name: Log in to Docker Hub
        if: ${{ inputs.push }}
        uses: docker/login-action@v3.6.0
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      - name: Run build_vllm_docker.py
        id: run
        shell: bash
        env:
          GITHUB_OUTPUT: ${{ env.GITHUB_OUTPUT }}
        run: |
          set -euo pipefail
          python3 ./build_tools/build_vllm_docker.py \
            --pytorch-base-image "${{ inputs.pytorch_base_image }}" \
            --vllm-repo "${{ inputs.vllm_repo }}" \
            --vllm-ref "${{ inputs.vllm_ref }}" \
            --final-image-name "${{ inputs.final_image_name }}" \
            --rocm-version "${{ inputs.rocm_version }}" \
            --amdgpu-family "${{ inputs.amdgpu_family }}" \
            --push "${{ inputs.push }}" \
            --write-outputs

      - name: Summary
        run: |
          echo "vLLM image built: ${{ steps.run.outputs.vllm_tag }}"
