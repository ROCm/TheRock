name: Strix AI/ML Testing

# Runs automatically on push/PR to Strix test files, or manually on demand
on:
  # Automatic triggers
  push:
    branches:
      - 'users/*/strix_*'      # Any user's strix branch
      - 'main'                  # Main branch
      - 'develop'               # Develop branch
    paths:
      - 'tests/strix_ai/**'     # Strix AI tests
      - '.github/workflows/strix_ai*.yml'  # This workflow
      - 'build_tools/_therock_utils/**'    # Utilities used by tests
  
  pull_request:
    branches:
      - 'main'
      - 'develop'
    paths:
      - 'tests/strix_ai/**'
      - '.github/workflows/strix_ai*.yml'
  
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      platform:
        description: 'Platform to test'
        required: true
        type: choice
        options:
          - linux
          - windows
        default: 'linux'
      
      strix_variant:
        description: 'Strix GPU variant'
        required: true
        type: choice
        options:
          - gfx1150  # Strix Point
          - gfx1151  # Strix Halo
        default: 'gfx1151'
      
      test_category:
        description: 'Test category to run'
        required: true
        type: choice
        options:
          - all       # Run all tests
          - vlm       # Vision Language Models
          - vla       # Vision Language Action
          - vit       # Vision Transformers
          - cv        # Computer Vision
          - optimization  # Quantization & optimization
          - quick     # Quick smoke tests only
        default: 'quick'
      
      test_type:
        description: 'Test execution type'
        required: true
        type: choice
        options:
          - smoke     # Quick validation
          - quick     # Reduced test set
          - full      # Complete test suite
        default: 'quick'
      
      runner_label:
        description: 'GitHub runner label (leave default unless testing)'
        required: false
        type: string
        default: ''

permissions:
  contents: read

jobs:
  strix_ai_test:
    name: Strix AI Tests
    runs-on: ${{ github.event.inputs.runner_label || ((github.event.inputs.platform || 'linux') == 'linux' && 'linux-strix-halo-gpu-rocm' || 'windows-strix-halo-gpu-rocm') }}
    timeout-minutes: 120
    
    # Linux: Use ROCm PyTorch container with everything pre-installed
    # Using :latest for now - can pin to specific SHA256 digest later for reproducibility
    # To pin to SHA: docker pull rocm/pytorch:latest
    #                 docker inspect --format='{{index .RepoDigests 0}}' rocm/pytorch:latest
    # Available tags: https://hub.docker.com/r/rocm/pytorch/tags
    container:
      image: ${{ (github.event.inputs.platform || 'linux') == 'linux' && 'rocm/pytorch:latest' || null }}
      options: ${{ (github.event.inputs.platform || 'linux') == 'linux' && '--ipc host --group-add video --device /dev/kfd --device /dev/dri --group-add 110 --user 0:0' || '' }}
    
    defaults:
      run:
        shell: bash
    
    env:
      # Note: Using rocm/pytorch container - no need for artifact/venv management
      AMDGPU_FAMILIES: ${{ github.event.inputs.strix_variant || 'gfx1151' }}
      TEST_TYPE: ${{ github.event.inputs.test_type || 'quick' }}
      TEST_CATEGORY: ${{ github.event.inputs.test_category || 'all' }}
      PLATFORM: ${{ github.event.inputs.platform || 'linux' }}
      PYTHONUNBUFFERED: 1
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          repository: "ROCm/TheRock"
          ref: ${{ github.ref }}
      
      # Note: Do NOT use actions/setup-python - it overrides container's ROCm Python!
      # The rocm/pytorch container already has Python + PyTorch with ROCm support
      
      - name: Display System Info
        run: |
          echo "=== Strix AI Test Run ==="
          echo "Trigger: ${{ github.event_name }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          echo "Platform: ${{ env.PLATFORM }}"
          echo "Strix Variant: ${{ env.AMDGPU_FAMILIES }}"
          echo "Test Category: ${{ env.TEST_CATEGORY }}"
          echo "Test Type: ${{ env.TEST_TYPE }}"
          echo "Runner: ${{ runner.name }}"
          echo ""
          echo "=== Python Info ==="
          which python3
          python3 --version
          which pip3
          pip3 --version
          echo "Python path: $(python3 -c 'import sys; print(sys.executable)')"
      
      # Linux-specific: Check GPU and ROCm
      - name: Check ROCm/GPU (Linux)
        if: env.PLATFORM == 'linux'
        run: |
          echo "=== Container/System Info ==="
          cat /etc/os-release || true
          uname -a
          
          echo ""
          echo "=== ROCm Info ==="
          if command -v rocminfo &> /dev/null; then
            echo "✓ ROCm is installed!"
            rocminfo | head -50 || true
          else
            echo "✗ WARNING: rocminfo not found in PATH"
            echo "This means ROCm is NOT installed in the container"
            echo "AI/ML tests may not be able to use the GPU"
          fi
          
          echo ""
          echo "=== HIP Info ==="
          if command -v hipconfig &> /dev/null; then
            echo "✓ HIP is available"
            hipconfig --version || true
          else
            echo "✗ WARNING: HIP not found"
          fi
          
          echo ""
          echo "=== GPU Devices ==="
          ls -la /dev/kfd /dev/dri/ || echo "GPU devices not accessible"
          
          echo ""
          echo "=== ROCm Environment Variables ==="
          env | grep -i rocm || echo "No ROCm env vars set"
          
          echo ""
          echo "=== Checking for ROCm Libraries ==="
          ldconfig -p | grep -i "rocm\|hip\|hsa" | head -20 || echo "No ROCm libraries found in ldconfig"
      
      # Windows-specific: Check GPU
      - name: Check GPU (Windows)
        if: env.PLATFORM == 'windows'
        run: |
          Write-Host "=== GPU Info ==="
          Get-WmiObject Win32_VideoController | Select-Object Name, DriverVersion
          
          Write-Host "=== Environment ==="
          Get-ChildItem Env: | Where-Object { $_.Name -like "*ROCM*" -or $_.Name -like "*HIP*" }
      
      # Note: No need to install ROCm or fetch artifacts - rocm/pytorch container has everything
      # No need for setup_test_environment - AI/ML tests run standalone with PyTorch
      
      - name: Install AI/ML Dependencies
        run: |
          echo "=== Installing AI/ML Dependencies ==="
          echo "Note: PyTorch with ROCm is pre-installed in rocm/pytorch container"
          echo "Installing additional AI/ML libraries for testing"
          echo ""
          
          # Verify we're using container's Python with ROCm
          echo "Checking PyTorch before installing additional deps:"
          python3 -c "import torch; print('PyTorch:', torch.__version__)"
          
          # Container already has PyTorch, just add testing libraries
          pip3 install --upgrade pip
          pip3 install pytest pytest-check
          
          echo "Installing transformers and accelerate..."
          pip3 install transformers accelerate || echo "WARNING: transformers install failed"
          
          echo "Installing computer vision libraries..."
          pip3 install ultralytics opencv-python pillow || echo "WARNING: CV libs install failed"
          
          echo "Installing additional dependencies..."
          pip3 install timm einops scipy matplotlib || echo "WARNING: Additional deps install failed"
          
          echo ""
          echo "SUCCESS: Dependency installation complete (check warnings above)"
      
      - name: Verify Dependencies  
        run: |
          echo "=== Installed Python Packages ==="
          python3 -m pip list | grep -E "pytest|transformers|torch|ultralytics" || echo "Some packages may not be installed"
          
          echo ""
          echo "=== Critical: PyTorch GPU Detection ==="
          python3 -c "import torch, sys; print('PyTorch:', torch.__version__); print('CUDA/ROCm available:', torch.cuda.is_available()); print('Device count:', torch.cuda.device_count() if torch.cuda.is_available() else 0); print('Device name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NONE'); sys.exit(0 if torch.cuda.is_available() else 1)" || { echo "ERROR: PyTorch cannot detect GPU - all tests will be SKIPPED!"; exit 1; }
      
      - name: Run Strix AI Tests - VLM
        if: env.TEST_CATEGORY == 'all' || env.TEST_CATEGORY == 'vlm'
        env:
          AMDGPU_FAMILIES: ${{ env.AMDGPU_FAMILIES }}
        run: |
          echo "=== Running VLM Tests ==="
          echo "AMDGPU_FAMILIES: $AMDGPU_FAMILIES"
          python3 -m pytest tests/strix_ai/vlm/ -v -s \
            --junit-xml=test-results-vlm.xml \
            || exit 0
      
      - name: Run Strix AI Tests - VLA
        if: env.TEST_CATEGORY == 'all' || env.TEST_CATEGORY == 'vla'
        env:
          AMDGPU_FAMILIES: ${{ env.AMDGPU_FAMILIES }}
        run: |
          echo "=== Running VLA Tests ==="
          echo "AMDGPU_FAMILIES: $AMDGPU_FAMILIES"
          python3 -m pytest tests/strix_ai/vla/ -v -s \
            --junit-xml=test-results-vla.xml \
            || exit 0
      
      - name: Run Strix AI Tests - ViT
        if: env.TEST_CATEGORY == 'all' || env.TEST_CATEGORY == 'vit'
        env:
          AMDGPU_FAMILIES: ${{ env.AMDGPU_FAMILIES }}
        run: |
          echo "=== Running ViT Tests ==="
          echo "AMDGPU_FAMILIES: $AMDGPU_FAMILIES"
          python3 -m pytest tests/strix_ai/vit/ -v -s \
            --junit-xml=test-results-vit.xml \
            || exit 0
      
      - name: Run Strix AI Tests - CV
        if: env.TEST_CATEGORY == 'all' || env.TEST_CATEGORY == 'cv'
        env:
          AMDGPU_FAMILIES: ${{ env.AMDGPU_FAMILIES }}
        run: |
          echo "=== Running CV Tests ==="
          echo "AMDGPU_FAMILIES: $AMDGPU_FAMILIES"
          python3 -m pytest tests/strix_ai/cv/ -v -s \
            --junit-xml=test-results-cv.xml \
            || exit 0
      
      - name: Run Strix AI Tests - Optimization
        if: env.TEST_CATEGORY == 'all' || env.TEST_CATEGORY == 'optimization'
        env:
          AMDGPU_FAMILIES: ${{ env.AMDGPU_FAMILIES }}
        run: |
          echo "=== Running Optimization Tests ==="
          echo "AMDGPU_FAMILIES: $AMDGPU_FAMILIES"
          python3 -m pytest tests/strix_ai/optimization/ -v -s \
            --junit-xml=test-results-optimization.xml \
            || exit 0
      
      - name: Run Strix AI Tests - Quick Smoke Tests
        if: env.TEST_CATEGORY == 'all' || env.TEST_CATEGORY == 'quick'
        env:
          AMDGPU_FAMILIES: ${{ env.AMDGPU_FAMILIES }}
        run: |
          echo "=== Running Quick Smoke Tests ==="
          echo "AMDGPU_FAMILIES: $AMDGPU_FAMILIES"
          python3 -m pytest tests/strix_ai/ -v -s \
            -m "quick" \
            --junit-xml=test-results-quick.xml \
            || exit 0
      
      - name: Display Test Results
        if: always()
        run: |
          echo "=== Test Results Summary ==="
          for xml_file in test-results-*.xml; do
            if [ -f "$xml_file" ]; then
              echo ""
              echo "##################################################"
              echo "## Results from: $xml_file"
              echo "##################################################"
              cat "$xml_file"
              echo ""
            fi
          done
          
          if [ ! -f test-results-*.xml ]; then
            echo "No test result XML files found"
          fi
      
      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: strix-ai-test-results-${{ env.PLATFORM }}-${{ env.AMDGPU_FAMILIES }}-${{ env.TEST_CATEGORY }}
          path: test-results-*.xml
          if-no-files-found: warn
          retention-days: 30
      
      - name: Test Summary
        if: always()
        run: |
          echo "=== Strix AI Test Summary ==="
          echo "Trigger: ${{ github.event_name }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Platform: ${{ env.PLATFORM }}"
          echo "Strix Variant: ${{ env.AMDGPU_FAMILIES }}"
          echo "Test Category: ${{ env.TEST_CATEGORY }}"
          echo "Test Type: ${{ env.TEST_TYPE }}"
          echo "Runner: ${{ runner.name }}"
          echo "Status: ${{ job.status }}"
          
          if [ -f test-results-*.xml ]; then
            echo "Test results saved to artifacts"
          fi

  # Optional: Run on multiple platforms in parallel
  strix_ai_test_matrix:
    name: 'Strix AI Matrix Tests'
    # Only run if triggered manually with 'all' category and 'full' test type
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_category == 'all' && github.event.inputs.test_type == 'full'
    strategy:
      fail-fast: false
      matrix:
        platform: [linux, windows]
        category: [vlm, vla, vit, cv]
    runs-on: ${{ matrix.platform == 'linux' && 'linux-strix-halo-gpu-rocm' || 'windows-strix-halo-gpu-rocm' }}
    timeout-minutes: 60
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Dependencies
        run: |
          python3 -m pip install pytest transformers ultralytics opencv-python pillow
      
      - name: Run Tests
        env:
          AMDGPU_FAMILIES: ${{ github.event.inputs.strix_variant || 'gfx1151' }}
        run: |
          python3 -m pytest tests/strix_ai/${{ matrix.category }}/ -v

