name: Test JAX  Wheels and Build Docker

on:
  workflow_call:
    inputs:
      amdgpu_family:
        description: AMD GPU family directory in S3 (e.g., gfx94X-dcgpu)
        required: true
        type: string
      release_type:
        description: The type of release ("nightly" or "dev")
        required: true
        type: string
      s3_subdir:
        description: S3 subdirectory (e.g., v2 or v2-staging)
        required: true
        type: string
      rocm_version:
        description: ROCm version to use in docker build (e.g., 5.12)
        required: true
        type: string
      tar_url:
        description: URL to TheRock tarball to build against
        required: true
        type: string
      python_versions:
        description: Python version string used to compute CP tag (e.g., 3.12 -> cp312)
        required: true
        type: string
      jax_ref:
        description: Branch/tag/sha of rocm/rocm-jax to build
        required: false
        type: string
        default: master
      jax_test_branch:
        description: JAX test repo branch to get unit tests from
        required: false
        type: string
        default: "rocm-jaxlib-v0.7.1"

  workflow_dispatch:
    inputs:
      amdgpu_family:
        type: choice
        options:
          - gfx110X-dgpu
          - gfx1151
          - gfx120X-all
          - gfx94X-dcgpu
          - gfx950-dcgpu
        default: gfx94X-dcgpu
      release_type:
        type: choice
        options: [dev, nightly]
        default: dev
      s3_subdir:
        type: string
        default: v2-staging
      rocm_version:
        type: string
        required: true
      tar_url:
        type: string
        required: true
      python_versions:
        type: string
        required: true
        default: "3.12"
      jax_ref:
        type: string
        default: master
      jax_test_branch:
        type: string
        description: JAX test repo branch to get unit tests from
        default: "rocm-jaxlib-v0.7.1"

permissions:
  contents: read
  packages: write

jobs:
  build_test_push:
    name: Build and Test JAX | ${{ inputs.amdgpu_family }}
    runs-on: ${{ github.repository_owner == 'ROCm' && 'azure-linux-scale-rocm' || 'ubuntu-24.04' }}
    env:
      S3_BUCKET_PY: therock-${{ inputs.release_type }}-python
      WHEELHOUSE_DIR: ${{ github.workspace }}/jax/wheelhouse
    steps:
      - name: Checkout TheRock
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Checkout rocm-jax (plugin + build scripts)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          path: jax
          repository: rocm/rocm-jax
          ref: ${{ inputs.jax_ref }}

      - name: Setup Python
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: "3.12"

      - name: Install AWS CLI
        run: bash ./dockerfiles/install_awscli.sh

      - name: Prepare wheelhouse and download JAX wheels
        shell: bash
        working-directory: jax
        run: |
          set -euo pipefail
          mkdir -p "${WHEELHOUSE_DIR}"
          AWS_FLAGS="--no-sign-request"
          PY_VER="${{ inputs.python_versions }}"
          CP="${PY_VER//./}"
          BASE_S3_URL_WHL="s3://${{ env.S3_BUCKET_PY }}/${{ inputs.s3_subdir }}/${{ inputs.amdgpu_family }}/"

          echo "Copying wheels from ${BASE_S3_URL_WHL} -> ${WHEELHOUSE_DIR}"
          echo "Using Python ${PY_VER}, CP=${CP}"

          # Plugin wheel
          aws s3 cp "${BASE_S3_URL_WHL}" "${WHEELHOUSE_DIR}/" \
            --recursive \
            --exclude "*" \
            --include "jax_rocm7_plugin-*-cp${CP}-cp${CP}-manylinux_*_x86_64.whl" \
            ${AWS_FLAGS}

          # PJRT wheel
          aws s3 cp "${BASE_S3_URL_WHL}" "${WHEELHOUSE_DIR}/" \
            --recursive \
            --exclude "*" \
            --include "jax_rocm7_pjrt-*-py3-none-manylinux_*_x86_64.whl" \
            ${AWS_FLAGS}
          echo "Contents of wheelhouse:"
          pwd
          ls -lah "${WHEELHOUSE_DIR}"

      - name: Build JAX Docker image
        working-directory: jax
        env:
          ROCM_VERSION: ${{ inputs.rocm_version }}
        run: |
          set -euo pipefail

          # Extract major.minor.patch from ROCM_VERSION
          # e.g., "7.9.0.dev0+abcdef" -> "7.9.0"
          # Replacement: \1.\2.\3 reconstructs the version as "major.minor.patch" using the three captured groups.
          ROCM_SEMVER="$(echo "${ROCM_VERSION}" | sed -E 's/^([0-9]+)\.([0-9]+)\.([0-9]+).*/\1.\2.\3/')"
          echo "Full ROCm version: ${ROCM_VERSION}"
          echo "Using semantic ROCm version: ${ROCM_SEMVER}"

          python3 build/ci_build \
            --rocm-version="${ROCM_SEMVER}" \
            --therock-path="${{ inputs.tar_url }}" \
            build_dockers \
            -f ubu24

          echo "Local images after build:"
          docker images --format '{{.Repository}}:{{.Tag}} {{.ID}}' | sort

      - name: Checkout JAX tests repo (for extended tests)
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          repository: rocm/jax
          ref: ${{ inputs.jax_test_branch }}
          path: jax/jax_tests

      - name: Run unit tests
        working-directory: jax
        env:
          ROCM_VERSION: ${{ inputs.rocm_version }}
        run: |
          set -euo pipefail
          # Compute image name to match ci_build tag: ubu24.rocm<maj><min><patch>
          ROCM_SEMVER="$(echo "${ROCM_VERSION}" | sed -E 's/^([0-9]+)\.([0-9]+)\.([0-9]+).*/\1.\2.\3/')"
          IMAGE_NAME="jax-ubu24.rocm$(echo "${ROCM_SEMVER}" | tr -d '.')"
          echo "Running CPU-only tests in image: ${IMAGE_NAME}"
          # Run tests without GPU device flags and force CPU mode
          docker run --rm -i \
            -v "${PWD}:/rocm-jax" \
            --shm-size 16G \
            "${IMAGE_NAME}" \
            bash -c 'cd /rocm-jax && JAX_PLATFORM_NAME=cpu JAX_PLATFORMS=cpu pytest jax_tests/tests/core_test.py'
            # TODO
            # Analyze single_gpu_test and add GPU based tests

