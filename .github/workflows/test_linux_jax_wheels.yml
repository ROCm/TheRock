name: Test JAX  Wheels and Build Docker

on:
  workflow_call:
    inputs:
      amdgpu_family:
        description: AMD GPU family directory in S3 (e.g., gfx94X-dcgpu)
        required: true
        type: string
      release_type:
        description: The type of release ("nightly" or "dev")
        required: true
        type: string
      s3_subdir:
        description: S3 subdirectory (e.g., v2 or v2-staging)
        required: true
        type: string
      rocm_version:
        description: ROCm version to use in docker build (e.g., 5.12)
        required: true
        type: string
      tar_url:
        description: URL to TheRock tarball to build against
        required: true
        type: string
      python_versions:
        description: Python version string used to compute CP tag (e.g., 3.12 -> cp312)
        required: true
        type: string
      jax_ref:
        description: Branch/tag/sha of rocm/rocm-jax to build
        required: false
        type: string
        default: master
  workflow_dispatch:
    inputs:
      amdgpu_family:
        type: choice
        options:
          - gfx110X-dgpu
          - gfx1151
          - gfx120X-all
          - gfx94X-dcgpu
          - gfx950-dcgpu
        default: gfx94X-dcgpu
      release_type:
        type: choice
        options: [dev, nightly]
        default: dev
      s3_subdir:
        type: string
        default: v2-staging
      rocm_version:
        type: string
        required: true
      tar_url:
        type: string
        required: true
      python_versions:
        type: string
        required: true
        default: "3.12"
      jax_ref:
        type: string
        default: master

permissions:
  id-token: write
  contents: read
  packages: write

jobs:
  build_test_push:
    name: Build, Test, then Push JAX Docker | ${{ inputs.amdgpu_family }}
    runs-on: ${{ github.repository_owner == 'ROCm' && 'azure-linux-scale-rocm' || 'ubuntu-24.04' }}
    env:
      S3_BUCKET_PY: therock-${{ inputs.release_type }}-python
      WHEELHOUSE_DIR: ${{ github.workspace }}/jax/jax_rocm_plugin/wheelhouse
    steps:
      - name: Checkout TheRock
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      - name: Checkout rocm-jax
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          path: jax
          repository: rocm/rocm-jax
          ref: ${{ inputs.jax_ref }}

      - name: Setup Python
        uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v6.0.0
        with:
          python-version: "3.12"

      - name: Install AWS CLI
        run: bash ./dockerfiles/install_awscli.sh

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@7474bc4690e29a8392af63c5b98e7449536d5c3a # v4.3.1
        with:
          aws-region: us-east-2
          role-to-assume: arn:aws:iam::692859939525:role/therock-${{ inputs.release_type }}-releases

      - name: Prepare wheelhouse and download JAX wheels (combined, optimized)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${WHEELHOUSE_DIR}"

          PY_VER="${{ inputs.python_versions }}"
          CP="${PY_VER//./}"
          BASE="s3://${{ env.S3_BUCKET_PY }}/${{ inputs.s3_subdir }}/${{ inputs.amdgpu_family }}/"

          echo "Copying wheels from ${BASE} -> ${WHEELHOUSE_DIR}"
          echo "Using Python ${PY_VER}, CP=${CP}"

          # Plugin wheel
          aws s3 cp "${BASE}" "${WHEELHOUSE_DIR}/" \
            --recursive \
            --exclude "*" \
            --include "jax_rocm7_plugin-*-cp${CP}-cp${CP}-manylinux_*_x86_64.whl"

          # PJRT wheel
          aws s3 cp "${BASE}" "${WHEELHOUSE_DIR}/" \
            --recursive \
            --exclude "*" \
            --include "jax_rocm7_pjrt-*-py3-none-manylinux_*_x86_64.whl"

          ls -lah "${WHEELHOUSE_DIR}"

      - name: Build JAX Docker image (ubu24)
        working-directory: jax
        env:
          ROCM_VERSION: ${{ inputs.rocm_version }}
        run: |
          set -euo pipefail
          python3 build/ci_build \
            --rocm-version="${ROCM_VERSION}" \
            --therock-path="${{ inputs.tar_url }}" \
            build_dockers \
            -f ubu24

          echo "Local images after build:"
          docker images --format '{{.Repository}}:{{.Tag}} {{.ID}}' | sort

      - name: Run unit tests (on local image)
        working-directory: jax
        env:
          IMAGE_NAME: jax-ubu24.rocm${{ inputs.rocm_version && inputs.rocm_version != '' && '' || '' }}
        run: |
          set -euo pipefail
          # Local image name expected from build: jax-ubu24.rocm${ROCM_VERSION//.}
          IMAGE_NAME="jax-ubu24.rocm${ROCM_VERSION//.}"
          echo "Running tests in image: ${IMAGE_NAME}"
          python3 build/ci_build test "${IMAGE_NAME}" \
            --test-cmd "pytest jax/tests/core_test.py"
            # TODO will enable another test after basic sanity running on GPU nodes
            # --test-cmd "pytest jax/tests/linalg_test.py"
            # TODO will enable another test after basic sanity tests
            #--test-cmd "python jax_rocm_plugin/build/rocm/run_single_gpu.py -c"

      - name: Log in to GHCR
        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567 # v3.3.0
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Push docker image to Container Registry
        env:
          ROCM_VERSION: ${{ inputs.rocm_version }}
        run: |
          set -euo pipefail
          ubu24_img="ghcr.io/rocm/jax-ubu24.therock.${ROCM_VERSION//.}:${GITHUB_SHA}"
          echo "Ubuntu 24 image name: ${ubu24_img}"
          docker images
          docker tag "jax-ubu24.rocm${ROCM_VERSION//.}" "${ubu24_img}"
          docker push "${ubu24_img}"
